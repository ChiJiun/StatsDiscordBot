import json
import re
import openai
import os
import datetime
import docx
import markdown
import asyncio
from concurrent.futures import ThreadPoolExecutor
from config import OPENAI_API_KEY, MODEL, SPECIFIC_PROMPTS


class GradingService:
    # æ·»åŠ ç·šç¨‹æ± åŸ·è¡Œå™¨ï¼ˆé¡åˆ¥å±¤ç´šï¼‰
    _executor = ThreadPoolExecutor(max_workers=2)
    
    @staticmethod
    def get_grading_prompts(question_title=None):
        """
        Get grading prompts from config.py based on question title
        Returns: 
            (eng_prompt, stat_prompt) or (None, None) if not found
        """
        # å¦‚æœæ²’æœ‰æä¾›é¡Œç›®æ¨™é¡Œï¼Œç›´æ¥è¿”å› None
        if not question_title:
            return None, None
        
        # âœ… ä¿®æ”¹ï¼šåš´æ ¼æª¢æŸ¥ï¼Œåªæœ‰åœ¨ SPECIFIC_PROMPTS æœ‰å®šç¾©æ™‚æ‰å›å‚³
        if question_title in SPECIFIC_PROMPTS:
            prompt_config = SPECIFIC_PROMPTS[question_title]
            
            # ç¢ºä¿ prompt_config æ˜¯å­—å…¸
            if isinstance(prompt_config, dict):
                eng_prompt_file = prompt_config.get("english")
                stat_prompt_file = prompt_config.get("statistics")
                print(f"ğŸ¯ é¡Œç›® '{question_title}' æ‰¾åˆ°å°ˆå±¬ Prompt")
            else:
                print(f"âš ï¸ è­¦å‘Šï¼šé¡Œç›® '{question_title}' çš„ prompt é…ç½®æ ¼å¼éŒ¯èª¤")
                return None, None
        else:
            # âŒ å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®š promptï¼Œç›´æ¥è¿”å› Noneï¼Œä¸ä½¿ç”¨é è¨­å€¼
            print(f"â„¹ï¸ é¡Œç›® '{question_title}' å°šæœªè¨­å®š Promptï¼Œåœæ­¢è©•åˆ†")
            return None, None
        
        # è®€å– prompt æª”æ¡ˆå…§å®¹
        eng_prompt = GradingService._read_prompt_file(eng_prompt_file)
        stat_prompt = GradingService._read_prompt_file(stat_prompt_file)
        
        if not eng_prompt or not stat_prompt:
            print(f"âŒ ç„¡æ³•è®€å– prompt æª”æ¡ˆ: {eng_prompt_file}, {stat_prompt_file}")
            return None, None
        
        return eng_prompt, stat_prompt

    @staticmethod
    def _read_prompt_file(file_path):
        """
        Read prompt content from file
        Args:
            file_path (str): Path to the prompt file
        Returns:
            str: Content of the prompt file
        """
        if not file_path or not os.path.exists(file_path):
            print(f"âŒ Prompt æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            return None
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # print(f"âœ… æˆåŠŸè®€å– prompt æª”æ¡ˆ: {file_path}")
                return content
        except Exception as e:
            print(f"âŒ è®€å– prompt æª”æ¡ˆå¤±æ•—: {file_path}, éŒ¯èª¤: {e}")
            return None

    # ---------- Student Data Extraction ----------
    @staticmethod
    def extract_student_data(file_path):
        """
        Read .docx file: first line is student name, subsequent lines are answer.
        """
        doc = docx.Document(file_path)
        paras = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
        if paras:
            name = paras[0]
            answer = "\n".join(paras[1:])
        else:
            name, answer = "Unknown", ""
        return name, answer

    # ---------- OpenAI Interaction ----------
    @staticmethod
    def create_messages(prompt, student_name, student_answer):
        """
        Construct messages for ChatGPT: system prompt + student data.
        """
        user_msg = (
            f"Student Name: {student_name}\n"
            f"Student Answer:\n{student_answer}\n"
            "Please evaluate the student's performance according to the system instructions."
        )
        return [
            {"role": "system", "content": prompt},
            {"role": "user",   "content": user_msg}
        ]

    @staticmethod
    def _generate_feedback_sync(messages, model=None, temperature=1.0):
        """åŒæ­¥å‘¼å« OpenAI APIï¼ˆåœ¨åŸ·è¡Œç·’æ± ä¸­åŸ·è¡Œï¼‰"""
        import openai
        
        if model is None:
            model = MODEL
        
        openai.api_key = OPENAI_API_KEY
        
        try:
            response = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"âŒ OpenAI API å‘¼å«å¤±æ•—: {e}")
            raise

    @staticmethod
    async def generate_feedback(messages, model=None, temperature=1.0):
        """
        éåŒæ­¥ç”Ÿæˆè©•åˆ†åé¥‹
        """
        loop = asyncio.get_event_loop()
        
        feedback = await loop.run_in_executor(
            GradingService._executor,
            GradingService._generate_feedback_sync,
            messages,
            model,
            temperature
        )
        
        return feedback

    # ---------- Report Generation ----------
    @staticmethod
    def create_html_report(feedback, student_name, output_file):
        """
        Generate an HTML report with embedded CSS styling.
        """
        css = """
        <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f8f9fa; }
        .report-container { background-color: #fff; border: 1px solid #ccc; padding: 20px; }
        table { border-collapse: collapse; width: 100%; margin-top: 20px; }
        table, th, td { border: 1px solid #000; }
        th { background-color: #D9E1F2; padding: 8px; text-align: center; }
        td { background-color: #F2F2F2; padding: 8px; text-align: left; }
        </style>
        """
        html_body = markdown.markdown(feedback, extensions=['tables','fenced_code'])
        full_html = (
            f"<!DOCTYPE html><html><head><meta charset='utf-8'><title>Feedback Report</title>{css}</head>"
            f"<body><h2>{student_name}</h2><div class='report-container'>{html_body}</div>"
            f"</body></html>"
        )
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(full_html)